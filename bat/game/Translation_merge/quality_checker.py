#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¿»è¯‘è´¨é‡æ£€æŸ¥æ¨¡å—
æ£€æµ‹æ¼ç¿»ã€è¯­åºé”™è¯¯ç­‰é—®é¢˜
"""

import json
import re
from typing import Dict, List, Tuple
from pathlib import Path


def contains_japanese(text: str) -> bool:
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æ—¥æ–‡å­—ç¬¦ï¼ˆå¹³å‡åã€ç‰‡å‡åï¼‰"""
    for char in text:
        code = ord(char)
        if (0x3040 <= code <= 0x309F or  # å¹³å‡å
                0x30A0 <= code <= 0x30FF):  # ç‰‡å‡å
            return True
    return False


def should_skip_for_quality_check(text: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡è´¨é‡æ£€æŸ¥ï¼ˆæŠ€æœ¯å†…å®¹ã€ç¬¦å·ç­‰ï¼‰"""
    text = str(text).strip()
    
    # ç©ºæ–‡æœ¬
    if not text:
        return True
    
    # çº¯ç¬¦å·ä¸²ï¼ˆå¦‚ ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ã€ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ã€â—†ãƒ¼ãƒ¼ãƒ¼â—† ç­‰ï¼‰
    unique_chars = set(text.replace(' ', '').replace('\u3000', ''))
    if len(unique_chars) <= 3:
        if all(c in 'ãƒ¼ãƒ»â—†â– â–²â—â˜…â˜†ï½â€¦ã€ã€‚ï¼ï¼Ÿâ€•_-=+' for c in unique_chars):
            return True
    
    # æ¸¸æˆè„šæœ¬æ ‡ç­¾ <xxx:...>
    if re.match(r'^<[^>]+>$', text):
        return True
    
    # ä»£ç /æ—¥å¿—
    if 'console.log' in text or 'function(' in text:
        return True
    
    # æ–‡ä»¶å
    if re.match(r'^.*\.(png|jpg|json|motion3\.json|pic)$', text, re.IGNORECASE):
        return True

    # æ–‡ä»¶/ç›®å½•è·¯å¾„ï¼ˆåŒ…å«2ä¸ªä»¥ä¸Šæ–œæ çš„è·¯å¾„æ ¼å¼ï¼‰
    if text.count('/') >= 2 or text.count('\\') >= 2:
        return True
    
    # çº¯å‡åå­—ç¬¦è¡¨ï¼ˆå­—ä½“æµ‹è¯•ï¼‰
    if len(text) > 50 and calculate_japanese_ratio(text) > 0.9:
        return True
    
    return False


def calculate_japanese_ratio(text: str) -> float:
    """è®¡ç®—æ—¥æ–‡å­—ç¬¦å æ¯”"""
    if not text:
        return 0.0
    
    jp_count = 0
    total_count = 0
    
    for char in text:
        if char.strip():  # å¿½ç•¥ç©ºç™½å­—ç¬¦
            total_count += 1
            code = ord(char)
            if (0x3040 <= code <= 0x309F or  # å¹³å‡å
                    0x30A0 <= code <= 0x30FF):  # ç‰‡å‡å
                jp_count += 1
    
    return jp_count / total_count if total_count > 0 else 0.0


def check_missing_translation(original: str, translated: str) -> Tuple[bool, str]:
    """
    æ£€æµ‹æ¼ç¿»
    
    Returns:
        (æ˜¯å¦æ¼ç¿», åŸå› æè¿°)
    """
    original = str(original).strip()
    translated = str(translated).strip()
    
    # 1. åŸæ–‡ä¸è¯‘æ–‡å®Œå…¨ç›¸åŒ
    if original == translated and contains_japanese(original):
        return True, "åŸæ–‡æœªç¿»è¯‘"
    
    # 2. è¯‘æ–‡ä¸­æ—¥æ–‡å æ¯”è¿‡é«˜
    jp_ratio = calculate_japanese_ratio(translated)
    if jp_ratio > 0.3:
        return True, f"æ—¥æ–‡å æ¯” {jp_ratio:.0%}"
    
    return False, ""


def check_word_order_errors(translated: str) -> Tuple[bool, str, str]:
    """
    æ£€æµ‹è¯­åºé”™è¯¯
    
    Returns:
        (æ˜¯å¦æœ‰é”™è¯¯, é”™è¯¯ç±»å‹, åŒ¹é…åˆ°çš„å†…å®¹)
    """
    translated = str(translated).strip()
    
    # å®šä¹‰æ£€æµ‹æ¨¡å¼ - æ›´ç²¾ç¡®çš„è¯­åºé”™è¯¯æ¨¡å¼
    patterns = [
        # çœŸæ­£çš„è¯­åºé”™è¯¯ï¼šæ•°å­—åç›´æ¥è·Ÿä¸­æ–‡åŠ¨è¯/ä»‹è¯ï¼Œä½†æ’é™¤æ­£å¸¸çš„ "Xå¯¹Y" "Xåˆ°Y" æ ¼å¼
        # å¦‚ "3è¯·åœ¨" æ˜¯é”™è¯¯çš„ï¼Œä½† "2å¯³1" æ˜¯æ­£ç¡®çš„
        (r'\d+è¯·', "è¯­åºé”™è¯¯"),  # å¦‚ "3è¯·åœ¨æ—¥å†…"
        
        # æ•°å­—åè·Ÿæ–¹ä½è¯åè·Ÿé‡è¯ï¼ˆé¡ºåºé”™è¯¯ï¼‰
        # å¦‚ "1åå°æ—¶" åº”è¯¥æ˜¯ "1å°æ—¶å"
        (r'\d+(å|å‰|å†…|é‡Œ)(å°æ—¶|åˆ†é’Ÿ|å¤©|æ—¥|å¹´|æœˆ|å‘¨|æ¬¡|å›|ä¸ª)', "æ—¶é—´é‡è¯é”™ä½"),
        
        # æ—¥æ–‡æ®‹ç•™åç´§è·Ÿä¸­æ–‡
        # å¦‚ "3æ—¥è¯·åœ¨" 
        (r'\d+[ã-ã‚“ã‚¡-ãƒ³]+(è¯·|åœ¨|æŠŠ|è¢«|æ˜¯|æœ‰)', "æ—¥æ–‡æ®‹ç•™"),
        
        # åŠ©è¯æœªç¿»è¯‘
        (r'[ãŒã¯ã‚’ã«ã§ã¨ã®ã‚‚ã¸ã‚„ã‹ãª][ï¼Œã€‚ï¼ï¼Ÿ]', "åŠ©è¯æœªç¿»è¯‘"),
    ]
    
    for pattern, error_type in patterns:
        match = re.search(pattern, translated)
        if match:
            return True, error_type, match.group()
    
    return False, "", ""
    
    for pattern, error_type in patterns:
        match = re.search(pattern, translated)
        if match:
            return True, error_type, match.group()
    
    return False, "", ""


def check_translation_quality(original_file: str, translated_file: str, 
                             check_missing: bool = True,
                             check_order: bool = True) -> Dict:
    """
    æ£€æŸ¥ç¿»è¯‘è´¨é‡
    
    Args:
        original_file: åŸæ–‡æ–‡ä»¶è·¯å¾„
        translated_file: è¯‘æ–‡æ–‡ä»¶è·¯å¾„
        check_missing: æ˜¯å¦æ£€æµ‹æ¼ç¿»
        check_order: æ˜¯å¦æ£€æµ‹è¯­åºé”™è¯¯
        
    Returns:
        æ£€æŸ¥ç»“æœå­—å…¸
    """
    # åŠ è½½æ–‡ä»¶
    with open(original_file, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    with open(translated_file, 'r', encoding='utf-8') as f:
        translated_data = json.load(f)
    
    results = {
        "total_entries": len(translated_data),
        "missing_translations": [],
        "word_order_errors": [],
        "summary": {}
    }
    
    for key, translated in translated_data.items():
        original = original_data.get(key, key)
        
        # è·³è¿‡æŠ€æœ¯å†…å®¹
        if should_skip_for_quality_check(original):
            continue
        
        # æ£€æµ‹æ¼ç¿»
        if check_missing:
            is_missing, reason = check_missing_translation(original, translated)
            if is_missing:
                results["missing_translations"].append({
                    "key": key,
                    "original": original,
                    "translated": translated,
                    "reason": reason
                })
        
        # æ£€æµ‹è¯­åºé”™è¯¯
        if check_order:
            has_error, error_type, matched = check_word_order_errors(translated)
            if has_error:
                results["word_order_errors"].append({
                    "key": key,
                    "original": original,
                    "translated": translated,
                    "error_type": error_type,
                    "matched": matched
                })
    
    # æ±‡æ€»
    results["summary"] = {
        "missing_count": len(results["missing_translations"]),
        "order_error_count": len(results["word_order_errors"])
    }
    
    return results


def check_with_ai(translator, entries: List[Dict], batch_size: int = 15) -> List[Dict]:
    """
    ä½¿ç”¨AIæ£€æµ‹ç¿»è¯‘é—®é¢˜
    
    Args:
        translator: ç¿»è¯‘å™¨å®ä¾‹ï¼ˆç”¨äºè°ƒç”¨APIï¼‰
        entries: è¦æ£€æŸ¥çš„æ¡ç›®åˆ—è¡¨ [{"original": ..., "translated": ...}, ...]
        batch_size: æ¯æ‰¹å‘é€çš„æ¡ç›®æ•°
        
    Returns:
        æœ‰é—®é¢˜çš„æ¡ç›®åˆ—è¡¨
    """
    if not entries:
        return []
    
    issues = []
    
    # åˆ†æ‰¹å¤„ç†
    for i in range(0, len(entries), batch_size):
        batch = entries[i:i + batch_size]
        
        # æ„å»ºæ£€æŸ¥prompt
        prompt = """è¯·æ£€æŸ¥ä»¥ä¸‹æ—¥è¯‘ä¸­ç¿»è¯‘ï¼Œæ‰¾å‡ºå­˜åœ¨ä»¥ä¸‹é—®é¢˜çš„æ¡ç›®ï¼š
1. è¯­åºä¸é€šé¡º
2. ç¿»è¯‘ä¸å‡†ç¡®æˆ–æ„æ€åå·®
3. æ¼è¯‘æˆ–å¤šè¯‘

åªè¾“å‡ºæœ‰é—®é¢˜çš„ç¼–å·å’Œç®€çŸ­åŸå› ï¼Œæ ¼å¼å¦‚ï¼š
1: è¯­åºæ··ä¹±
5: ç¿»è¯‘ä¸å‡†ç¡®

å¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œè¾“å‡º"æ— é—®é¢˜"ã€‚

ç¿»è¯‘åˆ—è¡¨ï¼š
"""
        for idx, entry in enumerate(batch, 1):
            prompt += f"\n{idx}. åŸæ–‡: {entry['original']}\n   è¯‘æ–‡: {entry['translated']}\n"
        
        try:
            # è°ƒç”¨API
            response = translator.translate_single(prompt)
            
            # è§£æå“åº”
            if "æ— é—®é¢˜" not in response:
                # è§£æå‡ºæœ‰é—®é¢˜çš„ç¼–å·
                for line in response.strip().split('\n'):
                    match = re.match(r'(\d+)[ï¼š:]\s*(.+)', line.strip())
                    if match:
                        idx = int(match.group(1)) - 1
                        reason = match.group(2)
                        if 0 <= idx < len(batch):
                            entry = batch[idx]
                            # è¿‡æ»¤æ— æ•ˆç»“æœï¼šçº¯æ•°å­—ã€éæ—¥æ–‡ç›¸åŒå†…å®¹ç­‰
                            orig = str(entry.get('original', '')).strip()
                            trans = str(entry.get('translated', '')).strip()
                            # è·³è¿‡çº¯æ•°å­—æ¡ç›®
                            if orig.isdigit() or (orig == trans and not contains_japanese(orig)):
                                continue
                            issues.append({
                                **entry,
                                "ai_reason": reason
                            })
        except Exception as e:
            print(f"AIæ£€æŸ¥å‡ºé”™: {e}")
            continue
    
    return issues


def fix_with_ai(translator, issues: List[Dict], batch_size: int = 10) -> Dict[str, str]:
    """
    ä½¿ç”¨AIä¿®å¤ç¿»è¯‘é—®é¢˜
    
    Args:
        translator: ç¿»è¯‘å™¨å®ä¾‹
        issues: é—®é¢˜æ¡ç›®åˆ—è¡¨ [{"key": ..., "original": ..., "translated": ..., ...}, ...]
        batch_size: æ¯æ‰¹å¤„ç†çš„æ¡ç›®æ•°
        
    Returns:
        ä¿®å¤åçš„ç¿»è¯‘å­—å…¸ {key: fixed_translation, ...}
    """
    if not issues:
        return {}
    
    fixed = {}
    
    # åˆ†æ‰¹å¤„ç†
    for i in range(0, len(issues), batch_size):
        batch = issues[i:i + batch_size]
        
        # æ„å»ºä¿®å¤prompt
        prompt = """è¯·ä¿®æ­£ä»¥ä¸‹æ—¥è¯‘ä¸­ç¿»è¯‘ä¸­çš„é—®é¢˜ã€‚å¯¹äºæ¯ä¸ªæ¡ç›®ï¼Œè¯·ç›´æ¥è¾“å‡ºä¿®æ­£åçš„ä¸­æ–‡ç¿»è¯‘ã€‚

æ³¨æ„ï¼š
1. ä¿æŒåŸæ„ï¼Œåªä¿®æ­£è¯­åºæˆ–è¡¥å……æ¼è¯‘
2. å¦‚æœæ˜¯è¯­åºé—®é¢˜å¦‚"3è¯·åœ¨æ—¥å†…"ï¼Œåº”æ”¹ä¸º"è¯·åœ¨3æ—¥å†…"
3. å¦‚æœæ˜¯æ¼è¯‘ï¼Œè¯·ç¿»è¯‘æˆä¸­æ–‡
4. æ¯è¡Œä¸€ä¸ªï¼Œæ ¼å¼ä¸ºï¼šç¼–å·. ä¿®æ­£åçš„ç¿»è¯‘

åŸæ–‡å’Œå½“å‰è¯‘æ–‡ï¼š
"""
        for idx, item in enumerate(batch, 1):
            prompt += f"\n{idx}. åŸæ–‡: {item['original']}\n   å½“å‰è¯‘æ–‡: {item['translated']}\n"
        
        try:
            response = translator.translate_single(prompt)
            
            # è§£æå“åº”
            lines = response.strip().split('\n')
            for line in lines:
                # åŒ¹é…æ ¼å¼ï¼šç¼–å·. ç¿»è¯‘å†…å®¹
                match = re.match(r'(\d+)[\.ã€]\s*(.+)', line.strip())
                if match:
                    idx = int(match.group(1)) - 1
                    fixed_text = match.group(2).strip()
                    if 0 <= idx < len(batch):
                        key = batch[idx].get('key', batch[idx].get('original'))
                        original = batch[idx].get('original', '')
                        old_trans = batch[idx].get('translated', '')
                        
                        # éªŒè¯ä¿®å¤ç»“æœæ˜¯å¦æœ‰æ•ˆ
                        # 1. ä¸åº”åŒ…å«promptæ±¡æŸ“
                        if 'åŸæ–‡:' in fixed_text or 'å½“å‰è¯‘æ–‡:' in fixed_text:
                            continue
                        # 2. ä¸åº”æ¯”åŸæ¥æ›´å·®ï¼ˆæ—¥æ–‡æ¯”ä¾‹ä¸åº”å¢åŠ ï¼‰
                        old_jp_ratio = calculate_japanese_ratio(old_trans)
                        new_jp_ratio = calculate_japanese_ratio(fixed_text)
                        if new_jp_ratio > old_jp_ratio and new_jp_ratio > 0.3:
                            continue
                        # 3. ä¸åº”æ˜¯çº¯æ—¥æ–‡
                        if new_jp_ratio > 0.8:
                            continue
                        # 4. ä¸åº”ä¸ºç©ºæˆ–å¤ªçŸ­
                        if len(fixed_text) < 2:
                            continue
                        
                        fixed[key] = fixed_text
        except Exception as e:
            print(f"AIä¿®å¤å‡ºé”™: {e}")
            continue
    
    return fixed


def apply_fixes(translated_file: str, fixes: Dict[str, str], output_file: str = None) -> int:
    """
    åº”ç”¨ä¿®å¤åˆ°ç¿»è¯‘æ–‡ä»¶
    
    Args:
        translated_file: åŸè¯‘æ–‡æ–‡ä»¶
        fixes: ä¿®å¤å­—å…¸ {key: fixed_translation}
        output_file: è¾“å‡ºæ–‡ä»¶(é»˜è®¤è¦†ç›–åŸæ–‡ä»¶)
        
    Returns:
        ä¿®å¤çš„æ¡ç›®æ•°
    """
    with open(translated_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    count = 0
    for key, fixed_value in fixes.items():
        if key in data:
            data[key] = fixed_value
            count += 1
    
    output = output_file or translated_file
    with open(output, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return count


def generate_report(results: Dict, output_file: str = None) -> str:
    """
    ç”Ÿæˆè´¨é‡æ£€æŸ¥æŠ¥å‘Š
    
    Args:
        results: æ£€æŸ¥ç»“æœ
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        æŠ¥å‘Šå†…å®¹
    """
    lines = []
    lines.append("=" * 60)
    lines.append("ç¿»è¯‘è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
    lines.append("=" * 60)
    lines.append(f"\næ€»æ¡ç›®æ•°: {results['total_entries']}")
    lines.append(f"æ¼ç¿»æ•°é‡: {results['summary']['missing_count']}")
    lines.append(f"è¯­åºé—®é¢˜: {results['summary']['order_error_count']}")
    
    if results["missing_translations"]:
        lines.append("\n" + "-" * 60)
        lines.append("ğŸ“‹ æ¼ç¿»æ¡ç›®")
        lines.append("-" * 60)
        for item in results["missing_translations"][:50]:  # æœ€å¤šæ˜¾ç¤º50æ¡
            lines.append(f"\nåŸæ–‡: {item['original']}")
            lines.append(f"è¯‘æ–‡: {item['translated']}")
            lines.append(f"åŸå› : {item['reason']}")
    
    if results["word_order_errors"]:
        lines.append("\n" + "-" * 60)
        lines.append("âš ï¸ è¯­åºé—®é¢˜")
        lines.append("-" * 60)
        for item in results["word_order_errors"][:50]:
            lines.append(f"\nåŸæ–‡: {item['original']}")
            lines.append(f"è¯‘æ–‡: {item['translated']}")
            lines.append(f"é—®é¢˜: {item['error_type']} (æ£€æµ‹åˆ°: {item['matched']})")
    
    if "ai_issues" in results and results["ai_issues"]:
        lines.append("\n" + "-" * 60)
        lines.append("ğŸ¤– AIæ£€æµ‹é—®é¢˜")
        lines.append("-" * 60)
        for item in results["ai_issues"][:50]:
            lines.append(f"\nåŸæ–‡: {item['original']}")
            lines.append(f"è¯‘æ–‡: {item['translated']}")
            lines.append(f"AIæ„è§: {item['ai_reason']}")
    
    report = "\n".join(lines)
    
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
    
    return report

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¸æˆç¿»è¯‘JSONæ–‡ä»¶åˆå¹¶å·¥å…·
æ¯”å¯¹ä¸¤ä¸ªç¿»è¯‘æ–‡ä»¶ï¼Œå°†å·²ç¿»è¯‘çš„å†…å®¹åˆå¹¶åˆ°æ–°æ–‡ä»¶ä¸­ï¼Œå¹¶æ‰¾å‡ºéœ€è¦ç¿»è¯‘çš„æ–°æ¡ç›®
"""

import json
import sys
import re
from pathlib import Path


def try_decode_mojibake(text):
    """
    å°è¯•ä¿®å¤ä¹±ç æ–‡æœ¬ï¼ˆmojibakeï¼‰
    å¸¸è§æƒ…å†µï¼šUTF-8æ–‡æœ¬è¢«è¯¯è®¤ä¸ºæ˜¯å…¶ä»–ç¼–ç 
    """
    if not text:
        return text, False

    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¯ç–‘çš„ä¹±ç å­—ç¬¦
    suspicious_chars = ['ï¿½', 'Ã¯', 'Ã¢', 'Ã£', 'Ã¤', 'Ã¥', 'Ã¦', 'Ã§', 'Ã¨', 'Ã©']
    has_suspicious = any(char in text for char in suspicious_chars)

    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§é‡åæ–œæ è½¬ä¹‰
    if '\\x' in text or has_suspicious:
        # å°è¯•å„ç§ç¼–ç ç»„åˆä¿®å¤
        encoding_pairs = [
            ('cp1252', 'utf-8'),  # Windowsè¯¯ç¼–ç 
            ('latin1', 'utf-8'),  # ISO-8859-1è¯¯ç¼–ç 
            ('cp932', 'utf-8'),  # Shift-JISè¯¯ç¼–ç 
            ('iso-8859-1', 'utf-8'),
        ]

        for wrong_enc, correct_enc in encoding_pairs:
            try:
                # å…ˆç”¨é”™è¯¯çš„ç¼–ç encodeï¼Œå†ç”¨æ­£ç¡®çš„ç¼–ç decode
                fixed = text.encode(wrong_enc).decode(correct_enc)
                # æ£€æŸ¥ä¿®å¤åæ˜¯å¦åŒ…å«æ—¥æ–‡å­—ç¬¦
                if contains_japanese(fixed):
                    return fixed, True
            except (UnicodeDecodeError, UnicodeEncodeError):
                continue

    return text, False


def contains_japanese(text):
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æ—¥æ–‡å­—ç¬¦ï¼ˆå¹³å‡åã€ç‰‡å‡åã€æ±‰å­—ï¼‰"""
    text = str(text)
    for char in text:
        code = ord(char)
        if (0x3040 <= code <= 0x309F or  # å¹³å‡å
                0x30A0 <= code <= 0x30FF or  # ç‰‡å‡å
                0x4E00 <= code <= 0x9FFF):  # æ±‰å­—(CJK)
            return True
    return False


def is_skip_entry(key, value):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡çš„æ¡ç›®ï¼ˆä¸éœ€è¦ç¿»è¯‘ï¼‰"""
    key_str = str(key).strip()
    value_str = str(value).strip()

    # keyå’Œvalueå¿…é¡»ç›¸åŒæ‰è€ƒè™‘è·³è¿‡ï¼ˆæœªç¿»è¯‘çš„æ¡ç›®ï¼‰
    if key_str != value_str:
        return False

    # ç©ºå­—ç¬¦ä¸²
    if not value_str:
        return True

    # çº¯æ•°å­—ï¼ˆåŒ…å«å°æ•°ç‚¹å’Œé€—å·åˆ†éš”çš„åæ ‡ï¼‰
    if re.match(r'^[\d,\.]+$', value_str):
        return True

    # æ¸¸æˆè„šæœ¬æ ‡ç­¾ <xxx:yyy> æˆ– <xxx>
    if re.match(r'^<[A-Za-z\u4e00-\u9fffã-ã‚“ã‚¡-ãƒ³]+[:ï¼š]?.*>$', value_str):
        return True
    
    # ä»¥å°–æ‹¬å·åŒ…è£¹çš„æŠ€æœ¯æ ‡ç­¾
    if value_str.startswith('<') and value_str.endswith('>'):
        return True
    
    # æ–‡ä»¶å¼•ç”¨ (xxx.pic, xxx.pngç­‰)
    if re.match(r'^.*\.(pic|png|jpg|mp3|ogg|wav|json|js|txt)$', value_str, re.IGNORECASE):
        return True
    
    # çº¯è‹±æ–‡æ ‡è¯†ç¬¦ (ST_xxx, map_xxx, blockç­‰)
    if re.match(r'^[A-Za-z_][A-Za-z0-9_]*$', value_str):
        return True
    
    # ä¸‹åˆ’çº¿åˆ†éš”çš„æŠ€æœ¯åç§°
    if re.match(r'^[A-Za-z0-9_]+$', value_str) and '_' in value_str:
        return True
    
    # é‡å¤çš„ç¬¦å·ä¸²ï¼ˆå¦‚ ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ï¼‰
    if len(value_str) >= 3:
        unique_chars = set(value_str.replace(' ', '').replace('ã€€', ''))
        if len(unique_chars) <= 2:
            return True

    # å°è¯•ä¿®å¤å¯èƒ½çš„ä¹±ç 
    fixed_text, was_fixed = try_decode_mojibake(value_str)
    if was_fixed:
        # å¦‚æœä¿®å¤æˆåŠŸï¼Œè¯´æ˜åŸæ–‡æ˜¯æ—¥æ–‡ï¼Œä¸åº”è¯¥è·³è¿‡
        return False

    # ä¸åŒ…å«æ—¥æ–‡å­—ç¬¦çš„å…¨éƒ¨è·³è¿‡ï¼ˆçº¯è‹±æ–‡ã€ç¬¦å·ã€ä»£ç ç­‰ï¼‰
    if not contains_japanese(value_str):
        return True

    # çº¯ç¬¦å·ä¸²ï¼ˆé‡å¤çš„â– â—†â–²ï¼Ÿï¼ç­‰ï¼‰
    if len(set(value_str)) <= 3:
        unique_chars = set(value_str)
        if all(c in 'â– â—†â–²â—ï¼Ÿï¼â€¦ï¼šï¼‹ï¼Ã—Ã·ï¼ã€€ ' for c in unique_chars):
            return True

    # åŒ…å«æ˜æ˜¾çš„ä»£ç ç‰¹å¾
    code_patterns = [
        r'var\s+', r'function\s*\(', r'this\.', r'=>', r'return\s+',
        r'console\.', r'Math\.', r'Graphics\.',
        r'http://', r'https://',
        r'\{.*\}', r'\[.*\]',
        r'\.js', r'\.css', r'\.png', r'\.mp3',
        r'//', r'\\n', r'\\t',
        r'rgba\(', r'url\(',
        r'ã‚³ãƒ¢ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆ\d+ï¼š',  # é€šç”¨äº‹ä»¶æ ‡ç­¾
        r'PictureLive2D',  # Live2DæŠ€æœ¯æ ‡ç­¾
    ]
    for pattern in code_patterns:
        if re.search(pattern, value_str):
            return True

    # åŒ…å«ä»£ç ç¬¦å·çš„ï¼ˆä½†å…è®¸æ—¥æ–‡ä¸­çš„å…¨è§’ç¬¦å·ï¼‰
    if any(c in value_str for c in ['=', '{', '}', '[', ']', ';']):
        # å¦‚æœåŒæ—¶åŒ…å«è¿™äº›ç¬¦å·ï¼Œå¯èƒ½æ˜¯ä»£ç 
        return True

    return False


def load_json(filepath):
    """åŠ è½½JSONæ–‡ä»¶"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
        sys.exit(1)


def save_json(data, filepath):
    """ä¿å­˜JSONæ–‡ä»¶"""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ–‡ä»¶å·²ä¿å­˜: {filepath}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
        sys.exit(1)


def find_json_files(path):
    """åœ¨è·¯å¾„ä¸­æŸ¥æ‰¾JSONæ–‡ä»¶"""
    path_obj = Path(path)

    # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç›´æ¥è¿”å›
    if path_obj.is_file() and path_obj.suffix.lower() == '.json':
        return [path_obj]

    # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    if path_obj.is_dir():
        json_files = list(path_obj.glob('*.json'))
        return json_files

    return []


def select_file(path_input, description):
    """é€‰æ‹©æ–‡ä»¶ï¼Œæ”¯æŒæ–‡ä»¶å¤¹è‡ªåŠ¨æŸ¥æ‰¾"""
    path_obj = Path(path_input)

    if not path_obj.exists():
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path_input}")
        sys.exit(1)

    # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç›´æ¥è¿”å›
    if path_obj.is_file():
        if path_obj.suffix.lower() != '.json':
            print(f"âŒ ä¸æ˜¯JSONæ–‡ä»¶: {path_input}")
            sys.exit(1)
        return str(path_obj)

    # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œåˆ—å‡ºæ‰€æœ‰JSONæ–‡ä»¶ä¾›é€‰æ‹©
    if path_obj.is_dir():
        json_files = list(path_obj.glob('*.json'))

        if not json_files:
            print(f"âŒ æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶: {path_input}")
            sys.exit(1)

        if len(json_files) == 1:
            print(f"âœ… è‡ªåŠ¨é€‰æ‹©å”¯ä¸€çš„JSONæ–‡ä»¶: {json_files[0].name}")
            return str(json_files[0])

        print(f"\nğŸ“ åœ¨æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶:")
        for idx, file in enumerate(json_files, 1):
            print(f"  {idx}. {file.name}")

        while True:
            try:
                choice = input(f"\nè¯·é€‰æ‹©{description} (1-{len(json_files)}): ").strip()
                choice_idx = int(choice) - 1
                if 0 <= choice_idx < len(json_files):
                    selected = json_files[choice_idx]
                    print(f"âœ… å·²é€‰æ‹©: {selected.name}")
                    return str(selected)
                else:
                    print(f"âŒ è¯·è¾“å…¥ 1 åˆ° {len(json_files)} ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å·²å–æ¶ˆæ“ä½œ")
                sys.exit(0)

    print(f"âŒ æ— æ•ˆçš„è·¯å¾„: {path_input}")
    sys.exit(1)


def merge_translations(new_file, old_translated_file, output_file):
    """
    åˆå¹¶ç¿»è¯‘æ–‡ä»¶

    å‚æ•°:
        new_file: åªæœ‰åŸæ–‡çš„æ–°æ–‡ä»¶è·¯å¾„
        old_translated_file: æœ‰åŸæ–‡å’Œè¯‘æ–‡çš„æ—§æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    print("=" * 60)
    print("ğŸ”„ å¼€å§‹å¤„ç†ç¿»è¯‘æ–‡ä»¶...")
    print("=" * 60)

    # åŠ è½½æ–‡ä»¶
    new_data = load_json(new_file)
    old_data = load_json(old_translated_file)

    print(f"\nğŸ“– æ–°æ–‡ä»¶æ¡ç›®æ•°: {len(new_data)}")
    print(f"ğŸ“– æ—§æ–‡ä»¶æ¡ç›®æ•°: {len(old_data)}")

    # åˆ›å»ºæ—§æ–‡ä»¶çš„åŸæ–‡->è¯‘æ–‡æ˜ å°„
    translation_map = {}
    for key, value in old_data.items():
        translation_map[key] = value

    # åˆå¹¶æ•°æ®
    merged_data = {}
    matched_count = 0
    new_entries = []
    skipped_count = 0
    fixed_mojibake = []

    for idx, (key, value) in enumerate(new_data.items(), 1):
        if key in translation_map:
            # æ‰¾åˆ°åŒ¹é…çš„åŸæ–‡ï¼Œå¤åˆ¶è¯‘æ–‡
            merged_data[key] = translation_map[key]
            matched_count += 1
        else:
            # æ–°å¢çš„æ¡ç›®
            # å…ˆå°è¯•ä¿®å¤ä¹±ç 
            fixed_value, was_fixed = try_decode_mojibake(value)

            if was_fixed:
                # è®°å½•ä¿®å¤çš„ä¹±ç 
                merged_data[key] = fixed_value
                fixed_mojibake.append({
                    'index': idx,
                    'original': value,
                    'fixed': fixed_value
                })
                new_entries.append({
                    'index': idx,
                    'key': key,
                    'value': fixed_value,
                    'was_mojibake': True
                })
            else:
                # æœªä¿®å¤çš„ä¿æŒåŸæ ·
                merged_data[key] = value

                # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡ï¼ˆä¸éœ€è¦ç¿»è¯‘çš„ï¼‰
                if is_skip_entry(key, value):
                    skipped_count += 1
                else:
                    # åªè®°å½•éœ€è¦ç¿»è¯‘çš„æ–°æ¡ç›®
                    new_entries.append({
                        'index': idx,
                        'key': key,
                        'value': value,
                        'was_mojibake': False
                    })

    # ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶
    save_json(merged_data, output_file)

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡")
    print("=" * 60)
    print(f"âœ… åŒ¹é…å¹¶å¤åˆ¶çš„è¯‘æ–‡: {matched_count} æ¡")
    print(f"ğŸ”§ ä¿®å¤çš„ä¹±ç æ–‡æœ¬: {len(fixed_mojibake)} æ¡")
    print(f"â­ï¸  è‡ªåŠ¨è·³è¿‡çš„æ¡ç›®: {skipped_count} æ¡ (æ•°å­—/ä»£ç /ç¬¦å·/è‹±æ–‡)")
    print(f"ğŸ†• éœ€è¦ç¿»è¯‘çš„æ–°æ¡ç›®: {len(new_entries)} æ¡ (ä»…æ—¥æ–‡æ–‡æœ¬)")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶æ€»æ¡ç›®æ•°: {len(merged_data)} æ¡")

    # æ˜¾ç¤ºä¿®å¤çš„ä¹±ç 
    if fixed_mojibake:
        print("\n" + "=" * 60)
        print("ğŸ”§ å·²ä¿®å¤çš„ä¹±ç æ–‡æœ¬")
        print("=" * 60)
        for item in fixed_mojibake[:10]:  # æœ€å¤šæ˜¾ç¤ºå‰10æ¡
            print(f"\nç¬¬ {item['index']} è¡Œ:")
            print(f"  åŸæ–‡(ä¹±ç ): {item['original']}")
            print(f"  ä¿®å¤å: {item['fixed']}")

        if len(fixed_mojibake) > 10:
            print(f"\n... è¿˜æœ‰ {len(fixed_mojibake) - 10} æ¡ä¹±ç å·²ä¿®å¤ ...")

    # æ˜¾ç¤ºæ–°å¢æ¡ç›®è¯¦æƒ…
    if new_entries:
        print("\n" + "=" * 60)
        print("ğŸ†• éœ€è¦ç¿»è¯‘çš„æ—¥æ–‡æ–°æ¡ç›®è¯¦æƒ…")
        print("=" * 60)

        # åˆ†åˆ«æ˜¾ç¤ºæ™®é€šæ¡ç›®å’Œä¿®å¤åçš„æ¡ç›®
        normal_entries = [e for e in new_entries if not e.get('was_mojibake')]
        mojibake_entries = [e for e in new_entries if e.get('was_mojibake')]

        if normal_entries:
            print("\nğŸ“ æ™®é€šæ—¥æ–‡æ¡ç›®:")
            for entry in normal_entries[:15]:  # æœ€å¤šæ˜¾ç¤ºå‰15æ¡
                print(f"  ç¬¬ {entry['index']} è¡Œ: {entry['value']}")
            if len(normal_entries) > 15:
                print(f"  ... è¿˜æœ‰ {len(normal_entries) - 15} æ¡ ...")

        if mojibake_entries:
            print(f"\nğŸ”§ ä¿®å¤åçš„æ¡ç›® (å…±{len(mojibake_entries)}æ¡ï¼Œå·²åŒ…å«åœ¨éœ€ç¿»è¯‘åˆ—è¡¨ä¸­)")

        # ä¿å­˜æ–°å¢æ¡ç›®åˆ°å•ç‹¬çš„æ–‡ä»¶
        new_entries_file = output_file.replace('.json', '_new_entries.json')
        new_entries_dict = {entry['key']: entry['value'] for entry in new_entries}
        save_json(new_entries_dict, new_entries_file)
        print(f"\nğŸ’¾ æ–°å¢æ¡ç›®å·²å•ç‹¬ä¿å­˜åˆ°: {new_entries_file}")
        print(f"   è¯¥æ–‡ä»¶åŒ…å« {len(new_entries)} æ¡éœ€è¦ç¿»è¯‘çš„æ—¥æ–‡æ–‡æœ¬")
        print(f"   (å…¶ä¸­ {len(mojibake_entries)} æ¡æ˜¯è‡ªåŠ¨ä¿®å¤çš„ä¹±ç )")
    else:
        print("\nâœ¨ æ²¡æœ‰æ–°å¢çš„æ—¥æ–‡æ–‡æœ¬éœ€è¦ç¿»è¯‘ï¼")

    print("\n" + "=" * 60)
    print("âœ… å¤„ç†å®Œæˆï¼")
    print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ® æ¸¸æˆç¿»è¯‘JSONæ–‡ä»¶åˆå¹¶å·¥å…· v2.0")
    print("=" * 60)

    # è·å–æ–‡ä»¶è·¯å¾„
    print("\nè¯·æä¾›æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¯ä»¥æ‹–æ‹½åˆ°ç»ˆç«¯ï¼‰:")
    print("ğŸ’¡ æç¤º: å¦‚æœæä¾›æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¼šè‡ªåŠ¨åˆ—å‡ºå…¶ä¸­çš„JSONæ–‡ä»¶ä¾›é€‰æ‹©")

    new_file_input = input("\nğŸ“„ æ–°æ–‡ä»¶ï¼ˆåªæœ‰åŸæ–‡ï¼‰è·¯å¾„: ").strip().strip('"').strip("'")
    old_file_input = input("ğŸ“„ æ—§æ–‡ä»¶ï¼ˆæœ‰è¯‘æ–‡ï¼‰è·¯å¾„: ").strip().strip('"').strip("'")
    output_file = input("ğŸ’¾ è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆç›´æ¥å›è½¦é»˜è®¤ä¸º merged_translation.jsonï¼‰: ").strip().strip('"').strip("'")

    if not output_file:
        output_file = "merged_translation.json"

    # é€‰æ‹©æ–‡ä»¶
    new_file = select_file(new_file_input, "æ–°æ–‡ä»¶ï¼ˆåªæœ‰åŸæ–‡ï¼‰")
    old_file = select_file(old_file_input, "æ—§æ–‡ä»¶ï¼ˆæœ‰è¯‘æ–‡ï¼‰")

    # æ‰§è¡Œåˆå¹¶
    merge_translations(new_file, old_file, output_file)


if __name__ == "__main__":
    main()